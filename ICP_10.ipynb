{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IIojf9jesFca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #Basic packages for creating dataframes and loading dataset\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt #Package for visualization\n",
        "\n",
        "import re #importing package for Regular expression operations\n",
        "\n",
        "from sklearn.model_selection import train_test_split #Package for splitting the data\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder #Package for conversion of categorical to Numerical\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer #Tokenization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #Add zeros or crop based on the length\n",
        "from keras.models import Sequential #Sequential Neural Network\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #For layers in Neural Network\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OkNeIwOPtf4t",
        "outputId": "a02103b9-cbc2-4c72-e7b2-ed4164ce6925"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d32d1b4-b45f-429d-8e83-8819fa27f346\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d32d1b4-b45f-429d-8e83-8819fa27f346\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Sentiment (1).csv to Sentiment (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset as a Pandas DataFrame\n",
        "dataset = pd.read_csv(\"Sentiment (1).csv\", header=0)\n",
        "\n",
        "\n",
        "mask = dataset.columns.isin(['text', 'sentiment'])\n",
        "data = dataset.loc[:, mask]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F_9MkNrLtMPD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgLqKOk-wTI7",
        "outputId": "e1a939ca-8458-47cf-b631-75591b306a64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-cee1da567eb8>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
            "<ipython-input-8-cee1da567eb8>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') "
      ],
      "metadata": {
        "id": "kezr9unryjzm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ') \n",
        "tokenizer.fit_on_texts(data['text'].values) \n",
        "X = tokenizer.texts_to_sequences(data['text'].values) \n"
      ],
      "metadata": {
        "id": "rXTEJG_RyzqR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X) \n",
        "\n",
        "embed_dim = \n",
        "lstm_out = "
      ],
      "metadata": {
        "id": "TgLvgT52y30W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createmodel():\n",
        "    model = Sequential() #Sequential Neural Network\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1])) \n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) \n",
        "    model.add(Dense(3,activation='softmax')) \n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "zMTB8dQjy65b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder = LabelEncoder() \n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) \n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42) "
      ],
      "metadata": {
        "id": "OwETgBSZy-2X"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 \n",
        "model = createmodel() \n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) \n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size) \n",
        "print(score)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjFXx1rzDuS",
        "outputId": "5d36a12e-5648-404c-95ee-e1b5a0ef6a78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 61s - loss: 0.8218 - accuracy: 0.6444 - 61s/epoch - 209ms/step\n",
            "144/144 - 2s - loss: 0.7730 - accuracy: 0.6640 - 2s/epoch - 12ms/step\n",
            "0.7729825973510742\n",
            "0.6640454530715942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names) #metrics of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf2EvPG9zeic",
        "outputId": "fcb64a7a-0a95-4497-9b2c-532ae432fe36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('sentimentAnalysis.h5') #Saving the model"
      ],
      "metadata": {
        "id": "f3kajJNlzqml"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model \n",
        "model= load_model('sentimentAnalysis.h5') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpAA1CTIzt-9",
        "outputId": "79168d54-db94-4c24-b3ab-6ee7b41e4529"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(integer_encoded)\n",
        "print(data['sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDetTd52zzA1",
        "outputId": "2493ead4-8ac7-432f-9b78-22d24e685376"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence)\n",
        "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0) \n",
        "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] \n",
        "\n",
        "print(sentiment_probs)\n",
        "if sentiment == 0:\n",
        "    print(\"Neutral\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Negative\")\n",
        "elif sentiment > 0:\n",
        "    print(\"Positive\")\n",
        "else:\n",
        "    print(\"Cannot be determined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmt0a-S8z3vM",
        "outputId": "606bf590-13a8-4653-915e-645741fd7db7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 278ms/epoch - 278ms/step\n",
            "[0.66862655 0.10003673 0.23133668]\n",
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "model = KerasClassifier(build_fn=createmodel,verbose=2) \n",
        "batch_size= [10, 20, 40] \n",
        "epochs = [1, 2] \n",
        "param_grid= {'batch_size':batch_size, 'epochs':epochs} \n",
        "grid  = GridSearchCV(estimator=model, param_grid=param_grid) \n",
        "grid_result= grid.fit(X_train,Y_train) \n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNyJbCLR1e3A",
        "outputId": "8a15e3b4-6313-4345-9172-1107a5023003"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-6c99b49150f4>:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=createmodel,verbose=2) #initiating model to test performance by applying multiple hyper parameters\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 113s - loss: 0.8287 - accuracy: 0.6472 - 113s/epoch - 152ms/step\n",
            "186/186 - 3s - loss: 0.7438 - accuracy: 0.6703 - 3s/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 108s - loss: 0.8189 - accuracy: 0.6508 - 108s/epoch - 145ms/step\n",
            "186/186 - 3s - loss: 0.7650 - accuracy: 0.6724 - 3s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 114s - loss: 0.8244 - accuracy: 0.6488 - 114s/epoch - 154ms/step\n",
            "186/186 - 2s - loss: 0.8078 - accuracy: 0.6541 - 2s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 112s - loss: 0.8279 - accuracy: 0.6464 - 112s/epoch - 151ms/step\n",
            "186/186 - 2s - loss: 0.7759 - accuracy: 0.6695 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 111s - loss: 0.8178 - accuracy: 0.6476 - 111s/epoch - 149ms/step\n",
            "186/186 - 3s - loss: 0.7714 - accuracy: 0.6647 - 3s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "744/744 - 109s - loss: 0.8275 - accuracy: 0.6461 - 109s/epoch - 146ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 97s - loss: 0.6825 - accuracy: 0.7107 - 97s/epoch - 130ms/step\n",
            "186/186 - 2s - loss: 0.7497 - accuracy: 0.6659 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "744/744 - 109s - loss: 0.8185 - accuracy: 0.6496 - 109s/epoch - 147ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 99s - loss: 0.6800 - accuracy: 0.7105 - 99s/epoch - 133ms/step\n",
            "186/186 - 2s - loss: 0.7490 - accuracy: 0.6815 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "744/744 - 107s - loss: 0.8224 - accuracy: 0.6442 - 107s/epoch - 144ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 98s - loss: 0.6794 - accuracy: 0.7139 - 98s/epoch - 131ms/step\n",
            "186/186 - 2s - loss: 0.7577 - accuracy: 0.6869 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "744/744 - 111s - loss: 0.8317 - accuracy: 0.6463 - 111s/epoch - 149ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 97s - loss: 0.6741 - accuracy: 0.7181 - 97s/epoch - 130ms/step\n",
            "186/186 - 2s - loss: 0.7587 - accuracy: 0.6690 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "744/744 - 108s - loss: 0.8180 - accuracy: 0.6455 - 108s/epoch - 146ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 99s - loss: 0.6638 - accuracy: 0.7153 - 99s/epoch - 134ms/step\n",
            "186/186 - 2s - loss: 0.7730 - accuracy: 0.6771 - 2s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 - 62s - loss: 0.8326 - accuracy: 0.6458 - 62s/epoch - 166ms/step\n",
            "93/93 - 1s - loss: 0.7516 - accuracy: 0.6627 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 - 62s - loss: 0.8325 - accuracy: 0.6469 - 62s/epoch - 166ms/step\n",
            "93/93 - 1s - loss: 0.7607 - accuracy: 0.6815 - 1s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 - 60s - loss: 0.8282 - accuracy: 0.6392 - 60s/epoch - 161ms/step\n",
            "93/93 - 2s - loss: 0.7611 - accuracy: 0.6826 - 2s/epoch - 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 - 62s - loss: 0.8335 - accuracy: 0.6395 - 62s/epoch - 167ms/step\n",
            "93/93 - 1s - loss: 0.7611 - accuracy: 0.6712 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 - 62s - loss: 0.8239 - accuracy: 0.6449 - 62s/epoch - 166ms/step\n",
            "93/93 - 1s - loss: 0.7787 - accuracy: 0.6604 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "372/372 - 62s - loss: 0.8356 - accuracy: 0.6469 - 62s/epoch - 167ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 49s - loss: 0.6832 - accuracy: 0.7090 - 49s/epoch - 132ms/step\n",
            "93/93 - 1s - loss: 0.7337 - accuracy: 0.6756 - 1s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "372/372 - 60s - loss: 0.8289 - accuracy: 0.6460 - 60s/epoch - 162ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 50s - loss: 0.6851 - accuracy: 0.7109 - 50s/epoch - 135ms/step\n",
            "93/93 - 1s - loss: 0.7370 - accuracy: 0.6794 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "372/372 - 63s - loss: 0.8306 - accuracy: 0.6386 - 63s/epoch - 170ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 50s - loss: 0.6782 - accuracy: 0.7186 - 50s/epoch - 135ms/step\n",
            "93/93 - 1s - loss: 0.7475 - accuracy: 0.6955 - 1s/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "372/372 - 61s - loss: 0.8237 - accuracy: 0.6438 - 61s/epoch - 165ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 48s - loss: 0.6771 - accuracy: 0.7119 - 48s/epoch - 129ms/step\n",
            "93/93 - 1s - loss: 0.7434 - accuracy: 0.6744 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "372/372 - 61s - loss: 0.8255 - accuracy: 0.6418 - 61s/epoch - 165ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 49s - loss: 0.6696 - accuracy: 0.7184 - 49s/epoch - 131ms/step\n",
            "93/93 - 1s - loss: 0.7911 - accuracy: 0.6631 - 1s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 - 39s - loss: 0.8511 - accuracy: 0.6363 - 39s/epoch - 208ms/step\n",
            "47/47 - 1s - loss: 0.7501 - accuracy: 0.6708 - 1s/epoch - 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 - 37s - loss: 0.8420 - accuracy: 0.6364 - 37s/epoch - 197ms/step\n",
            "47/47 - 1s - loss: 0.7642 - accuracy: 0.6708 - 748ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 - 36s - loss: 0.8463 - accuracy: 0.6333 - 36s/epoch - 196ms/step\n",
            "47/47 - 1s - loss: 0.7687 - accuracy: 0.6767 - 776ms/epoch - 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 - 38s - loss: 0.8570 - accuracy: 0.6363 - 38s/epoch - 202ms/step\n",
            "47/47 - 1s - loss: 0.7954 - accuracy: 0.6760 - 760ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 - 38s - loss: 0.8407 - accuracy: 0.6338 - 38s/epoch - 206ms/step\n",
            "47/47 - 1s - loss: 0.7700 - accuracy: 0.6668 - 766ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "186/186 - 36s - loss: 0.8448 - accuracy: 0.6361 - 36s/epoch - 196ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 26s - loss: 0.6962 - accuracy: 0.7010 - 26s/epoch - 140ms/step\n",
            "47/47 - 1s - loss: 0.7384 - accuracy: 0.6778 - 771ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "186/186 - 35s - loss: 0.8436 - accuracy: 0.6387 - 35s/epoch - 191ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 26s - loss: 0.6978 - accuracy: 0.7061 - 26s/epoch - 138ms/step\n",
            "47/47 - 1s - loss: 0.7313 - accuracy: 0.6767 - 946ms/epoch - 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "186/186 - 36s - loss: 0.8469 - accuracy: 0.6308 - 36s/epoch - 196ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 26s - loss: 0.6881 - accuracy: 0.7066 - 26s/epoch - 137ms/step\n",
            "47/47 - 1s - loss: 0.7470 - accuracy: 0.6853 - 762ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "186/186 - 36s - loss: 0.8475 - accuracy: 0.6324 - 36s/epoch - 192ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 25s - loss: 0.6922 - accuracy: 0.7053 - 25s/epoch - 136ms/step\n",
            "47/47 - 1s - loss: 0.7630 - accuracy: 0.6851 - 1s/epoch - 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "186/186 - 34s - loss: 0.8346 - accuracy: 0.6347 - 34s/epoch - 184ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 29s - loss: 0.6735 - accuracy: 0.7145 - 29s/epoch - 154ms/step\n",
            "47/47 - 1s - loss: 0.7676 - accuracy: 0.6819 - 846ms/epoch - 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "233/233 - 43s - loss: 0.8254 - accuracy: 0.6432 - 43s/epoch - 183ms/step\n",
            "Epoch 2/2\n",
            "233/233 - 35s - loss: 0.6820 - accuracy: 0.7081 - 35s/epoch - 149ms/step\n",
            "Best: 0.681374 using {'batch_size': 40, 'epochs': 2}\n"
          ]
        }
      ]
    }
  ]
}